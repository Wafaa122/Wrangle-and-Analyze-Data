{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wafaa N. Abu Dahrouj _Wrangle and Analyze Data \n",
    "Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import  packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as req\n",
    "import tweepy\n",
    "import json\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " df_enhanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-30 15:58:51 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891689557...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Darla</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-29 16:00:24 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Franklin. He would like you to stop ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891327558...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "2  891815181378084864                    NaN                  NaN   \n",
       "3  891689557279858688                    NaN                  NaN   \n",
       "4  891327558926688256                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "3  2017-07-30 15:58:51 +0000   \n",
       "4  2017-07-29 16:00:24 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "3  This is Darla. She commenced a snooze mid meal...                  NaN   \n",
       "4  This is Franklin. He would like you to stop ca...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "3  https://twitter.com/dog_rates/status/891689557...                13   \n",
       "4  https://twitter.com/dog_rates/status/891327558...                12   \n",
       "\n",
       "   rating_denominator      name doggo floofer pupper puppo  \n",
       "0                  10   Phineas  None    None   None  None  \n",
       "1                  10     Tilly  None    None   None  None  \n",
       "2                  10    Archie  None    None   None  None  \n",
       "3                  10     Darla  None    None   None  None  \n",
       "4                  10  Franklin  None    None   None  None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enhanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-16 00:24:50 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Here we have a 1949 1st generation vulpix. Enj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666049248...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-16 00:04:52 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is a purebred Piers Morgan. Loves to Netf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666044226...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-15 23:21:54 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Here is a very happy pup. Big fan of well-main...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666033412...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-15 23:05:30 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is a western brown Mitsubishi terrier. Up...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666029285...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-15 22:32:08 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Here we have a Japanese Irish Setter. Lost eye...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/666020888...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "2351  666049248165822465                    NaN                  NaN   \n",
       "2352  666044226329800704                    NaN                  NaN   \n",
       "2353  666033412701032449                    NaN                  NaN   \n",
       "2354  666029285002620928                    NaN                  NaN   \n",
       "2355  666020888022790149                    NaN                  NaN   \n",
       "\n",
       "                      timestamp  \\\n",
       "2351  2015-11-16 00:24:50 +0000   \n",
       "2352  2015-11-16 00:04:52 +0000   \n",
       "2353  2015-11-15 23:21:54 +0000   \n",
       "2354  2015-11-15 23:05:30 +0000   \n",
       "2355  2015-11-15 22:32:08 +0000   \n",
       "\n",
       "                                                 source  \\\n",
       "2351  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2352  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2353  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2354  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2355  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                   text  retweeted_status_id  \\\n",
       "2351  Here we have a 1949 1st generation vulpix. Enj...                  NaN   \n",
       "2352  This is a purebred Piers Morgan. Loves to Netf...                  NaN   \n",
       "2353  Here is a very happy pup. Big fan of well-main...                  NaN   \n",
       "2354  This is a western brown Mitsubishi terrier. Up...                  NaN   \n",
       "2355  Here we have a Japanese Irish Setter. Lost eye...                  NaN   \n",
       "\n",
       "      retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "2351                       NaN                        NaN   \n",
       "2352                       NaN                        NaN   \n",
       "2353                       NaN                        NaN   \n",
       "2354                       NaN                        NaN   \n",
       "2355                       NaN                        NaN   \n",
       "\n",
       "                                          expanded_urls  rating_numerator  \\\n",
       "2351  https://twitter.com/dog_rates/status/666049248...                 5   \n",
       "2352  https://twitter.com/dog_rates/status/666044226...                 6   \n",
       "2353  https://twitter.com/dog_rates/status/666033412...                 9   \n",
       "2354  https://twitter.com/dog_rates/status/666029285...                 7   \n",
       "2355  https://twitter.com/dog_rates/status/666020888...                 8   \n",
       "\n",
       "      rating_denominator  name doggo floofer pupper puppo  \n",
       "2351                  10  None  None    None   None  None  \n",
       "2352                  10     a  None    None   None  None  \n",
       "2353                  10     a  None    None   None  None  \n",
       "2354                  10     a  None    None   None  None  \n",
       "2355                  10  None  None    None   None  None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enhanced.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "II. df_breed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = req.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked the content type and separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text/tab-separated-values; charset=utf-8'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers['content-type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saved a path into a variable and read in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed = pd.read_csv(path, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "2  666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg   \n",
       "3  666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg   \n",
       "4  666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "2        1         German_shepherd  0.596461    True            malinois   \n",
       "3        1     Rhodesian_ridgeback  0.408143    True             redbone   \n",
       "4        1      miniature_pinscher  0.560311    True          Rottweiler   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2  0.138584    True           bloodhound  0.116197    True  \n",
       "3  0.360687    True   miniature_pinscher  0.222752    True  \n",
       "4  0.243682    True             Doberman  0.154629    True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_breed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Three_df_tweets Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"VLg1rGZGEbtl3aSy4HOu4zzzz\"\n",
    "consumer_secret = \"aA9xYwnBtMtRsJ3j8C1iurBwuFjfOB4MPEnOTj6itE4lwLzzzz\"\n",
    "access_token = '1304827952-wq5oVJHWCv07j8fSFRX2GCH0ntaT3Dxpr4pzzzz'\n",
    "access_secret = 'bBGqQo5a8aAfRboQR4X6GELydF3UtiaCM1vACE5NUzzzz'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of tweet ids to iterate through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = df_enhanced['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       892420643555336193\n",
       "1       892177421306343426\n",
       "2       891815181378084864\n",
       "3       891689557279858688\n",
       "4       891327558926688256\n",
       "5       891087950875897856\n",
       "6       890971913173991426\n",
       "7       890729181411237888\n",
       "8       890609185150312448\n",
       "9       890240255349198849\n",
       "10      890006608113172480\n",
       "11      889880896479866881\n",
       "12      889665388333682689\n",
       "13      889638837579907072\n",
       "14      889531135344209921\n",
       "15      889278841981685760\n",
       "16      888917238123831296\n",
       "17      888804989199671297\n",
       "18      888554962724278272\n",
       "19      888202515573088257\n",
       "20      888078434458587136\n",
       "21      887705289381826560\n",
       "22      887517139158093824\n",
       "23      887473957103951883\n",
       "24      887343217045368832\n",
       "25      887101392804085760\n",
       "26      886983233522544640\n",
       "27      886736880519319552\n",
       "28      886680336477933568\n",
       "29      886366144734445568\n",
       "               ...        \n",
       "2326    666411507551481857\n",
       "2327    666407126856765440\n",
       "2328    666396247373291520\n",
       "2329    666373753744588802\n",
       "2330    666362758909284353\n",
       "2331    666353288456101888\n",
       "2332    666345417576210432\n",
       "2333    666337882303524864\n",
       "2334    666293911632134144\n",
       "2335    666287406224695296\n",
       "2336    666273097616637952\n",
       "2337    666268910803644416\n",
       "2338    666104133288665088\n",
       "2339    666102155909144576\n",
       "2340    666099513787052032\n",
       "2341    666094000022159362\n",
       "2342    666082916733198337\n",
       "2343    666073100786774016\n",
       "2344    666071193221509120\n",
       "2345    666063827256086533\n",
       "2346    666058600524156928\n",
       "2347    666057090499244032\n",
       "2348    666055525042405380\n",
       "2349    666051853826850816\n",
       "2350    666050758794694657\n",
       "2351    666049248165822465\n",
       "2352    666044226329800704\n",
       "2353    666033412701032449\n",
       "2354    666029285002620928\n",
       "2355    666020888022790149\n",
       "Name: tweet_id, Length: 2356, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://stackoverflow.com/questions/34379168/how-to-save-the-tweets-in-json-to-txt-file-in-python-3-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "[{'code': 144, 'message': 'No status found with that ID.'}]\n"
     ]
    }
   ],
   "source": [
    "# creating a list for the exceptions\n",
    "exceptions_list = []\n",
    "\n",
    "# opening the file to write\n",
    "with open('tweet_json.txt', 'w', encoding = 'utf-8') as f:\n",
    "    for id_tweet in id_list: \n",
    "        try:\n",
    "            tweet = api.get_status(id_tweet, tweet_mode= 'extended')\n",
    "            json.dump(tweet._json, f)\n",
    "# writing the content witt new paragraphs\n",
    "            f.write(\"\\n\")\n",
    "        except Exception as e:\n",
    "            exceptions_list.append(id_tweet)\n",
    "# printing out the exception messages\n",
    "            print(str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the json file\n",
    "\n",
    "df_full_json = pd.read_json('tweet_json.txt', orient='records', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the columns to find out which values we would like to extract.\n",
    "\n",
    "df_full_json.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I should exclude retweets, I also want to know a tweet's retweet status.\n",
    "\n",
    "df_tweets = df_full_json[['id','favorite_count', 'retweet_count', 'retweeted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. df_tweets dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the df_tweets dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked the possible retweets in the dataset by counting the retweeted values. There are no any retweeted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tweets.query('retweeted == True'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked if there ary any duplicated value by id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[df_tweets['id'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After asessing, I can assume, that there are not any particular problem with this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. df_enhanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I printed out the archive dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I counted and grouped the dognames to discover the invalid dog names in the dataset. According to my observations, all the incorrect dog names start with a lower case letter and are detected as name based on the text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.groupby('name')['name'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced['name'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheking the null values and datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ckecked if there are any values duplicated by their id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced[df_enhanced['tweet_id'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. df_breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing the null values (if there are any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = df_breed.columns[df_breed.isnull().any()]\n",
    "df_breed[nulls].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "#### Tidiness:\n",
    "   \n",
    "- there are 3 dataset instead of 1 master dataset\n",
    "    \n",
    "df_enhanced dataset:\n",
    "    \n",
    "- unecessary source column with hardly readable information\n",
    "- unecessary category columns:  doggo, floofer, pupper, puppo \n",
    "    \n",
    "df_breed dataset:\n",
    "\n",
    "- no need of infos of some columns: \n",
    "- too many stages column instead of one\n",
    "- stages column could be categorical datatype\n",
    "    \n",
    "#### Quality:\n",
    "    \n",
    "df_enhanced dataset:\n",
    "    \n",
    "- the dog_stage is string datatype\n",
    "- unecessary rating denominator column, rating numerator column header without scale\n",
    "- incorrect names, missing names in name column: such?, quite, a, an, the... - all are written with lower case letters\n",
    "- retweeted records: retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp\n",
    "- missing data in name and stages columns showing as 'None'\n",
    "- incorrect datatypes: timestamp is string\n",
    "- in_reply_to_status_id, in_reply_to_user_id should be changed from sciantific float to string\n",
    "- wrong rating numeratores were extracted from the text column\n",
    "    \n",
    "df_breed dataset:\n",
    "    \n",
    "- dog breeds start with lower case letters\n",
    "- non-dog records in the dataset (eg.: shopping cart, box turtle...)\n",
    "- the p1, p2, p2 columns shoulf be categorical datatypes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. df_enhanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: \n",
    "Retweeted records in the dataset: retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code: \n",
    "I wanted to analyze the orignal ratings, so I deleted the retweeted tweets. I queried the records where the retweeted status was not null and dropped the values. I also dropped the unecessary retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I conted the number of retweeted tweets from df_enhanced dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_enhanced.query('retweeted_status_id != \"NaN\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a new dataframe without the retweeted tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = df_enhanced.query('retweeted_status_id == \"NaN\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doublechecking the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_enhanced.query('retweeted_status_id != \"NaN\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing, I dropped the unecessary empty columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = df_enhanced.drop(['retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: \n",
    "Unecessary rating denominator column, rating numerator column header without scale\n",
    "\n",
    "#### Code:\n",
    "\n",
    "I dropped the rating denominator column and add a scale to the numerator column in the title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I deleted the unecessary rating denominator column and renamed the rating numerator include and mark the rating denominator as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = df_enhanced.drop('rating_denominator', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = df_enhanced.rename(index=str, columns={\"rating_numerator\": \"rating_10_scale\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "There are incorrect numerators in the rating_numerator column (decimals are shown as integers)\n",
    "\n",
    "#### Code: \n",
    "I changed the datatype of the column and I extracted the right numerators of the text column with regex. \n",
    "I iterated through the df_enhanced database and changed the wrong values with the extracted data on each corresponding row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the rating_numerator columns, extract the right values from the text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the rating_10_scale column to float\n",
    "\n",
    "df_enhanced['rating_10_scale'] = df_enhanced['rating_10_scale'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save values into dataframe where text contains decimals\n",
    "df_bad_numerator = df_enhanced[df_enhanced.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]\n",
    "\n",
    "# creating a list to append the extracted values\n",
    "numerator = []\n",
    "\n",
    "for item in  df_bad_numerator['text']:\n",
    "    splitted = item.split('/')\n",
    "    numerator.append(splitted[0].split()[-1])\n",
    "print(numerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the corresponding tweet_ids into a list\n",
    "tweet_id_list = df_bad_numerator['tweet_id'].tolist()\n",
    "\n",
    "for i in range(len(tweet_id_list)):\n",
    "    # change the numerator in the oroginal dataframe\n",
    "    df_enhanced.loc[(df_enhanced['tweet_id'] == tweet_id_list[i]), ['rating_10_scale']] = numerator[i]\n",
    "    # test: print out the changed values in the original daraframe\n",
    "    print(df_enhanced.loc[(df_enhanced['tweet_id'] == tweet_id_list[i]), ['rating_10_scale']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "More issues regarding the name column: missing values, missing values marked as None, incorrect values\n",
    "\n",
    "#### Code:\n",
    "\n",
    "I decided to extract the dog names from the text columns to replace the missing values and correct the incorrect dog names. The valied dog names start with upper-case letters.\n",
    "\n",
    "I collect some of the cases and expressions when the dog names occur in the text column in the following context:\n",
    "    - ... named [Dog Name]\n",
    "    - meet [Dog Name]\n",
    "    - .. name is [Dog Name]\n",
    "    - This is [Dog Name]\n",
    "    - Say hello to [Dog Name]\n",
    "    - Meet [Dog Name]\n",
    "    - Here we have [Dog Name]\n",
    "    - Here is [Dog Name]\n",
    "    \n",
    "Then I will iterate through the text column and change the value in the name column based on the text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Creating two lists: one for the names we can' extract and one for the new names\n",
    "names_clean = []\n",
    "missing_names = []\n",
    "\n",
    "# Creating a lit of the texts\n",
    "text_list = df_enhanced['text'].values.tolist()\n",
    "\n",
    "# Creating a regex pattern\n",
    "pattern = re.compile('([A-Z].*)')\n",
    "\n",
    "# Iterating thourgh the text list and check if the content and pattern correspond to some of the extressions\n",
    "for text in df_enhanced['text']:\n",
    "    \n",
    "    if text.__contains__('This is') and pattern.fullmatch(text.split()[text.split().index(\"is\")+1]):\n",
    "        names_clean.append(text.split(\" \")[2].strip('.').strip(','))\n",
    "    elif text.startswith(\"Meet\") and pattern.fullmatch(text.split(\" \")[1]):\n",
    "        names_clean.append(text.split(\" \")[1].strip('.').strip(','))\n",
    "    elif text.startswith(\"Here we have\") and pattern.fullmatch(text.split(\" \", 3)[3]):\n",
    "        names_clean.append(text.split(\" \")[3].strip('.').strip(','))\n",
    "    elif text.split(\" \").__contains__(\"named\") and pattern.fullmatch(text.split()[text.split().index(\"named\")+1]):\n",
    "        names_clean.append(text.split()[text.split().index(\"named\")+1].strip('.').strip(','))\n",
    "    elif text.__contains__(\"name is\") and pattern.fullmatch(text.split()[text.split().index(\"is\")+1]):\n",
    "        names_clean.append(text.split()[text.split().index(\"is\")+1].strip('.').strip(','))\n",
    "    elif text.__contains__(\"Say hello to\") and pattern.fullmatch(text.split()[text.split().index(\"to\")+1]):\n",
    "        names_clean.append(text.split(\" \")[3].strip('.').strip(','))\n",
    "    else:\n",
    "        names_clean.append(\"NaN\")\n",
    "        missing_names.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of the missing names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I looked at the content to see if there are any dog names to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing, I saved the new names into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced['dog_name'] = names_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_enhanced['dog_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I compared the original names column with the new, cleaned one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced[['name']].groupby(['name'])['name'].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the new names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced[['dog_name']].groupby(['dog_name'])['dog_name'].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see at the bottom of the list, there are still some incorrect values with lower case letter. I replace them with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced['dog_name'] = df_enhanced['dog_name'].replace(to_replace = r'^([a-z])', value = np.nan, regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced[['dog_name']].groupby(['dog_name'])['dog_name'].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced[df_enhanced['dog_name'] == \"NaN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dropped the name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = df_enhanced.drop('name', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving the dog_name column forward, to the place of the old name column, using pop and ix.\n",
    "\n",
    "Source: https://stackoverflow.com/questions/25122099/move-column-by-name-to-front-of-table-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df_enhanced)\n",
    "\n",
    "cols.insert(8, cols.pop(cols.index('dog_name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = df_enhanced.ix[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Incorrect datatypes (timestamp, retweetd_status_id, retweeted_status_user_id, retweeted_status_timestamp)\n",
    "\n",
    "\n",
    "#### Code:\n",
    "Changing the incorrect data types:\n",
    "- timestamp\n",
    "- retweeted_status_id \n",
    "- retweeted_status_user_id \n",
    "- retweeted_status_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.timestamp = pd.to_datetime(df_enhanced.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the following post values with float datatype can not be converted to integer if there are any missing values and NaN data. I did not want to replace the missing values with 0 by using the fillna() function. So, I decided to convert the ids to object and scientific format to simple format. There is not any problem with that as we treat these id values as strings and do not expect to do any numerical operations with them anyway.\n",
    "\n",
    "https://stackoverflow.com/questions/41550746/error-using-astype-when-nan-exists-in-a-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used lambda and map function to convert floats in scientific format to simple string format in case of in_reply_to_status_id and in_reply_to_user_id.\n",
    "\n",
    "https://stackoverflow.com/questions/41157981/pandas-convert-float-in-scientific-notation-to-string/41158287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced['in_reply_to_status_id'] = df_enhanced.in_reply_to_status_id.map(lambda x: '{:.0f}'.format(x))\n",
    "df_enhanced['in_reply_to_user_id'] = df_enhanced.in_reply_to_user_id.map(lambda x: '{:.0f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test:\n",
    "\n",
    "I printed out the not null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced[df_enhanced['in_reply_to_status_id'] != 'nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: \n",
    "\n",
    "Unecessary category columns:  doggo, floofer, pupper, puppo\n",
    "\n",
    "#### Code:\n",
    "\n",
    "I merged the dog stage columns into one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_melt = df_enhanced.loc[ :, 'doggo' : 'puppo']\n",
    "columns_remain = df_enhanced.loc[:, 'tweet_id': 'dog_name']\n",
    "\n",
    "df_enhanced = pd.melt(df_enhanced, id_vars = columns_remain, value_vars = columns_melt, \n",
    "                         var_name = 'stages', value_name = 'dog_stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = df_enhanced.drop('stages', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is a lot of duplicated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.duplicated(subset = \"tweet_id\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I sorted and deleted the duplicate data. I had to keep the last records because the first had None values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = df_enhanced.sort_values('dog_stage').drop_duplicates('tweet_id', keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test:\n",
    "\n",
    "Double check the results: print out the lenght and count the duplicate data by id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.duplicated(subset = \"tweet_id\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Source column is not readable\n",
    "\n",
    "#### Code:\n",
    "\n",
    "I created a new user_source column based on the source column values.\n",
    "I dropped the unecessary long source column a create a new column based on the source values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_enhanced['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I extracted the source of the source column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = df_enhanced['source']\n",
    "\n",
    "user_source = []\n",
    "\n",
    "for item in df_enhanced['source']:\n",
    "    if item.__contains__(\"Twitter for iPhone\"):\n",
    "        user_source.append(\"Twitter for iPhone\")\n",
    "    elif item.__contains__(\"Twitter Web Client\"):\n",
    "        user_source.append(\"Twitter Web Client\")\n",
    "    elif item.__contains__('Vine - Make a Scene'):\n",
    "        user_source.append(\"Vine\")\n",
    "    elif item.__contains__('TweetDeck'):\n",
    "        user_source.append(\"TweetDeck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doublecheck if we could capture all the values. The output should be True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_source) == len(df_enhanced['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the list to the df_enhanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced['user_source'] = user_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced['user_source'].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the unecessary source column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = df_enhanced.drop(['source'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the datatype from string to categorical - user_source column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced['user_source'] = df_enhanced.user_source.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "\n",
    "There are 3 dataset instead of 1 master dataset\n",
    "\n",
    "#### Code:\n",
    "\n",
    "I merged the df_enhanced and df_tweets dataframe together by id values, using left join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.merge(left=df_enhanced,right=df_tweets, left_on='tweet_id', right_on='id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the unecessary id and retweeted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.drop(['id', 'retweeted'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning II: df_breed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    " Non-dog records in the dataset (eg.: shopping cart, box turtle...)\n",
    "\n",
    "#### Code:\n",
    "I observed that there are a lot of other things in the dataset, identified as dog by the neural network. As the predicitions was not always consistent and a lot of dog pictures was identified something else, too, I only dropped the rows, where none of the three predictions was identified as dogs. With this method, I could exclude as many incorrect data as possible and keep many good data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed.query('p1_dog == False and p2_dog == False and p3_dog == False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my observations, I decided keep as many data as possible, so I created a new dataframe with the values where any of the boolean columns is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed = df_breed.query('p1_dog == True or p2_dog == True or p3_dog == True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed.query('p1_dog == False and p2_dog == False and p3_dog == False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Dog breeds start with lower case letters and contain _ characters\n",
    "\n",
    "#### Code:\n",
    "I changed the first letter of the dog breeds from lower case letters to upper case letters and with remove() function I removed the _ characters to make the form consistent and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed['p1'] = df_breed.p1.str.capitalize()\n",
    "df_breed['p2'] = df_breed.p1.str.capitalize()\n",
    "df_breed['p3'] = df_breed.p1.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed['p1'].replace(regex=True,inplace=True,to_replace=\"_\",value=r' ')\n",
    "df_breed['p2'].replace(regex=True,inplace=True,to_replace=\"_\",value=r' ')\n",
    "df_breed['p3'].replace(regex=True,inplace=True,to_replace=\"_\",value=r' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_breed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "There are 3 dataset instead of 1 master dataset\n",
    "\n",
    "#### Code:\n",
    "\n",
    "Merging df_breed dataset with the df_clean dataset using left join to create one final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.merge(left=df_clean,right=df_breed, left_on='tweet_id', right_on='tweet_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test:\n",
    "Doublechecking the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "The p1, p2, p2 columns should be categorical datatypes\n",
    "\n",
    "#### Code:\n",
    "To make better analyzis, I decided to changing some datatypes to categorical in the master dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.dog_name = df_master.dog_name.astype('category');\n",
    "df_master.dog_stage = df_master.dog_stage.astype('category');\n",
    "df_master ['p1'] = df_master.p1.astype('category');\n",
    "df_master ['p2'] = df_master.p2.astype('category');\n",
    "df_master ['p3'] = df_master.p3.astype('category');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saved the dataset as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.to_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Possible Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller df with the numerical values to make a hetmap matrix of the correlations\n",
    "df_corr_values = df_master[['rating_10_scale', 'favorite_count', \n",
    "                               'retweet_count']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,8))\n",
    "correlation = df_corr_values.corr()\n",
    "\n",
    "sns.heatmap(correlation, \n",
    "            xticklabels=correlation.columns.values,\n",
    "            yticklabels=correlation.columns.values,\n",
    "            ax=ax,\n",
    "            linewidth= 0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no correlation between rating and favorite count and retweet count, which is absoluteli makes sense as rating is \"only\" part of the site's joke and can be absolutely random, not reflecting any particular meaning. However, we can find a correlation between favorite count and retweet count. That can be considered normal as more retweet means more favorites.\n",
    "\n",
    "I would like to find the most popular and loved dog breeds. As rating has not anything to do with popularity, I will rate popularity by retweets and favorites, assuming that the cuter the dog breed is the higher the retweets are.\n",
    "\n",
    "At first, I made a histogram of the most popular dogs on the site to get a closer look. I made a workaround to color the bar borders accoring to this issue: https://github.com/matplotlib/matplotlib/issues/9351/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Most Popular Dog Names on the Account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to find the most popular dog names. As rating has not anything to do with popularity, in this case, I will rate popularity by the number of tweets, assuming that the most popular dog names occur more times on the site.\n",
    "\n",
    "The most often tweeted dognames are Charlie, Lucy, Oliver and Cooper. Other names such as Lola, Daisy and Bella are also qiet popular. This trend corresponds my personal experience as I also consider these names popular among dog owners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "names = df_master['dog_name']\n",
    "names.value_counts().head(15).plot(kind = 'bar', color = \"#348A94\", ax = ax, edgecolor = ['Black']*len(names))\n",
    "ax.set_facecolor('#D3D3D3')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Most Beloved Breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, I analyzed the relationship between the numbers of favorite and dog breeds to find out which dog breeds are the most beloved by the users. I used the most relevant results of the machine learning values, categorized the dog breeds based on pictures. According to my results, golden retrivers are the all time favorites among the users with more than 1600000 favorites, the second and third breeds are labrador retrievers (about 1100000 favorites) and pembrokes (about 1000000 favorites). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a favorite dataframe by the groupped breeds, counted the favorites.\n",
    "df_favorite = df_master.groupby('p1')['favorite_count'].sum().reset_index()\n",
    "df_sorted = df_favorite.sort_values('favorite_count', ascending=False).head(10)\n",
    "ser_fav = df_sorted['favorite_count']\n",
    "ser_breed = df_sorted['p1']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fav = plt.barh(ser_breed, ser_fav, color = \"#C13016\", edgecolor = ['Black']*len(ser_breed))\n",
    "ax.set_facecolor('#D3D3D3')\n",
    "plt.xlabel('Number of Favorites')\n",
    "plt.title('Number of Favorites by Breed')\n",
    "plt.xticks(np.arange(200000, 1800000, 200000))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Dog Stages\n",
    "\n",
    "I analyzed the specific \"dog stages\", excluding the missing values to make a pie chart about the proportions of the categories. The most often used stage is \"pupper\" with more than 65%, the second one is \"doggo\" (about 22%). The account owners use the words puppo and floofer in 10% of the cases alltogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the cases where the dog stage is missing.\n",
    "df_stage = df_master[df_master['dog_stage'] != \"None\"]\n",
    "fig, ax = plt.subplots(figsize=(8.5,8.5))\n",
    "\n",
    "df_stage['dog_stage'].value_counts().plot(kind = 'pie', ax = ax, label = 'Dog Stage', autopct='%1.1f%%')\n",
    "plt.title('Proportion of Dog Stages')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV. Ratings\n",
    "\n",
    "I analyzed the portions of the ratings. I decided to use the qcut function to make the parts of the piechart almost equial and better readable. I gave the categories funny names to emphasize that higher rating often means cuter dogs. According to the results, most of the dogs are rated between 0 and 13, only 3% of the dogs are rated higher than 13. However, the highest rate is 1776! The numerators exceed the nominators in 40% of the cases, 40% of the dogs have higher ratings that 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the negative or null values from the dataframe\n",
    "df_cuteness = df_master[df_master['rating_10_scale'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cute_label = ['Good Dog (0.999, 9.0]', 'Adorable (9.0, 10.0]', 'Supertcute (10.0, 11.0]', 'Unbelieveable (11.0, 12.0]', 'Can I pet her pleeeeease?  (12.0, 13.0]', 'Who is the good boy? (13.0, 1776.0]']\n",
    "\n",
    "cute_bins = pd.qcut(df_cuteness['rating_10_scale'], 6, labels = cute_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8.5,8.5))\n",
    "cute_bins.value_counts().plot(kind = 'pie', ax = ax, label = 'Dog Stage', autopct='%1.1f%%')\n",
    "plt.title('Proportion of Dog Stages')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###25-12-2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
